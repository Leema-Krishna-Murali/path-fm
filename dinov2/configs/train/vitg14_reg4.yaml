dino:
  head_n_prototypes: 131072
  head_bottleneck_dim: 384
  do_kde: True
  kde_loss_weight: .05
  koleo_loss_weight: 0
  do_koleo: False
ibot:
  separate_head: true
  head_n_prototypes: 131072
train:
  OFFICIAL_EPOCH_LENGTH: 1250
  batch_size_per_gpu: 48
    #  dataset_path: ImageNet22k
  centering: sinkhorn_knopp
    # use_pretrained: True
student:
  arch: vit_giant2
  patch_size: 14
  drop_path_rate: 0.4
    #ffn_layer: mlp
  ffn_layer: swiglufused

  block_chunks: 4
  num_register_tokens: 4
    #  pretrained_weights: /home/dkaplan/.cache/torch/hub/checkpoints/dinov2_vits14_reg4_pretrain.pth
teacher:
  momentum_teacher: 0.994
optim:
  epochs: 500
  weight_decay_end: 0.2
  base_lr: 2.0e-04  # learning rate for a batch size of 1024
  warmup_epochs: 10
  layerwise_decay: 1.0
crops:
  local_crops_size: 98
evaluation:
  eval_period_iterations: 12500 # this is how often we will save ckpt! every 10 epochs