{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Configuration (litdata backend)\n",
    "import os, sys, math\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from omegaconf import OmegaConf\n",
    "import litdata as ld\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('/home/paul/path-fm')\n",
    "\n",
    "from dinov2.data import collate_data_and_cast, DataAugmentationDINO, MaskingGenerator\n",
    "\n",
    "# Load and merge config (ssl_default_config + vits14_reg4)\n",
    "cfg_default = OmegaConf.load('dinov2/configs/ssl_default_config.yaml')\n",
    "cfg_train = OmegaConf.load('dinov2/configs/train/vits14_reg4.yaml')\n",
    "cfg = OmegaConf.merge(cfg_default, cfg_train)\n",
    "\n",
    "# litdata storage options\n",
    "storage_options = {\n",
    "    'endpoint_url': os.environ.get('AWS_ENDPOINT_URL'),\n",
    "    'aws_access_key_id': os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "    'aws_secret_access_key': os.environ.get('AWS_SECRET_ACCESS_KEY'),\n",
    "}\n",
    "LITDATA_ROOT = 's3://sophont/paul/data/litTCGA'\n",
    "\n",
    "print('Merged config ready.')\n",
    "print(' litdata root:', LITDATA_ROOT)\n",
    "print(' crops: global', cfg.crops.global_crops_size, 'local', cfg.crops.local_crops_size)\n",
    "print(' patch_size:', cfg.student.patch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build augmentation, masking and collate exactly like in training\n",
    "img_size = cfg.crops.global_crops_size\n",
    "patch_size = cfg.student.patch_size\n",
    "n_tokens = (img_size // patch_size) ** 2\n",
    "\n",
    "mask_generator = MaskingGenerator(\n",
    "    input_size=(img_size // patch_size, img_size // patch_size),\n",
    "    max_num_patches=0.5 * img_size // patch_size * img_size // patch_size,\n",
    ")\n",
    "\n",
    "data_transform = DataAugmentationDINO(\n",
    "    cfg.crops.global_crops_scale,\n",
    "    cfg.crops.local_crops_scale,\n",
    "    cfg.crops.local_crops_number,\n",
    "    global_crops_size=cfg.crops.global_crops_size,\n",
    "    local_crops_size=cfg.crops.local_crops_size,\n",
    ")\n",
    "\n",
    "collate_fn = partial(\n",
    "    collate_data_and_cast,\n",
    "    mask_ratio_tuple=cfg.ibot.mask_ratio_min_max,\n",
    "    mask_probability=cfg.ibot.mask_sample_probability,\n",
    "    n_tokens=n_tokens,\n",
    "    mask_generator=mask_generator,\n",
    "    dtype=torch.half,\n",
    ")\n",
    "\n",
    "print('n_tokens:', n_tokens)\n",
    "print('cfg.crops.global_crops_size', cfg.crops.global_crops_size)\n",
    "print('cfg.crops.local_crops_size', cfg.crops.local_crops_size)\n",
    "print('mask_ratio_min_max:', list(cfg.ibot.mask_ratio_min_max))\n",
    "print('mask_probability:', cfg.ibot.mask_sample_probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create litdata StreamingDataset + DataLoader\n",
    "def extract_and_transform(item):\n",
    "    transformed = data_transform(item['image'])\n",
    "    return (transformed, None)\n",
    "\n",
    "dataset = ld.StreamingDataset(\n",
    "    LITDATA_ROOT,\n",
    "    storage_options=storage_options,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    transform=extract_and_transform,\n",
    ")\n",
    "\n",
    "data_loader = ld.StreamingDataLoader(dataset, collate_fn=collate_fn)\n",
    "batch = next(iter(data_loader))\n",
    "\n",
    "print('Batch keys:', list(batch.keys()))\n",
    "for k,v in batch.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(f' {k}: shape={tuple(v.shape)}, dtype={v.dtype}')\n",
    "\n",
    "actual_bs = batch['collated_global_crops'].shape[0] // 2\n",
    "print('Actual batch size (from crops):', actual_bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helpers and Global Crops\n",
    "IMAGENET_DEFAULT_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "IMAGENET_DEFAULT_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "def unnormalize_img(t):\n",
    "    x = t.detach().float().cpu().numpy()  # C,H,W\n",
    "    x = x * IMAGENET_DEFAULT_STD[:, None, None] + IMAGENET_DEFAULT_MEAN[:, None, None]\n",
    "    x = np.clip(x, 0.0, 1.0)\n",
    "    return np.transpose(x, (1,2,0))  # H,W,C\n",
    "\n",
    "def show_image_grid(imgs, ncols=4, title=None, figsize=(14, 6)):\n",
    "    n = len(imgs)\n",
    "    nrows = int(math.ceil(n / ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = np.array(axes).reshape(nrows, ncols) if n>1 else np.array([[axes]])\n",
    "    for i in range(nrows*ncols):\n",
    "        r, c = divmod(i, ncols)\n",
    "        ax = axes[r, c]\n",
    "        ax.axis('off')\n",
    "        if i < n:\n",
    "            ax.imshow(imgs[i])\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "global_crops = batch['collated_global_crops']  # [2*B, C, H, W]\n",
    "B = global_crops.shape[0] // 2\n",
    "to_show = []\n",
    "for i in range(min(B, 4)):\n",
    "    im1 = unnormalize_img(global_crops[2*i + 0])\n",
    "    im2 = unnormalize_img(global_crops[2*i + 1])\n",
    "    to_show.extend([im1, im2])\n",
    "show_image_grid(to_show, ncols=4, title='Global crops (pairs per sample)')\n",
    "\n",
    "print('Global crops tensor info:')\n",
    "print('  Shape:', tuple(global_crops.shape), '(2*B, C, H, W)')\n",
    "print('  Dtype:', global_crops.dtype)\n",
    "print(f'  Value range: [{global_crops.min():.3f}, {global_crops.max():.3f}]')\n",
    "print(f'  Mean: {global_crops.float().mean():.3f}, Std: {global_crops.float().std():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Crops\n",
    "local_crops = batch['collated_local_crops']  # [8*B, C, h, w] by default\n",
    "n_local = int(cfg.crops.local_crops_number)\n",
    "first_sample_locals = [unnormalize_img(local_crops[i]) for i in range(n_local)]\n",
    "show_image_grid(first_sample_locals, ncols=4, title='Local crops (first sample)')\n",
    "\n",
    "print('Local crops tensor info:')\n",
    "print('  Shape:', tuple(local_crops.shape), '(8*B, C, h, w)')\n",
    "print('  Dtype:', local_crops.dtype)\n",
    "print(f'  Value range: [{local_crops.min():.3f}, {local_crops.max():.3f}]')\n",
    "print(f'  Mean: {local_crops.float().mean():.3f}, Std: {local_crops.float().std():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iBOT Masks\n",
    "masks = batch['collated_masks']  # [2*B, N] where N=(img_size//patch_size)^2\n",
    "grid = img_size // patch_size\n",
    "n_show = min(masks.shape[0], 4)\n",
    "fig, axes = plt.subplots(1, n_show, figsize=(3*n_show, 3))\n",
    "if n_show == 1:\n",
    "    axes = [axes]\n",
    "for i in range(n_show):\n",
    "    m = masks[i].float().reshape(grid, grid).cpu().numpy()\n",
    "    axes[i].imshow(m, cmap='gray_r', vmin=0, vmax=1)\n",
    "    axes[i].set_title(f'Mask {i}')\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Mask statistics:')\n",
    "print('  Shape:', tuple(masks.shape), '(2*B, N)')\n",
    "print('  Dtype:', masks.dtype)\n",
    "print('  Total patches per image:', n_tokens)\n",
    "print('  Patches per side:', grid)\n",
    "for i in range(n_show):\n",
    "    mask_ratio = masks[i].float().mean().item()\n",
    "    print(f'  Sample {i+1}: {mask_ratio:.1%} masked ({masks[i].sum():.0f}/{n_tokens} patches)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathologydino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
